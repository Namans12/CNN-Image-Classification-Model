{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'C:/Users/naman/Desktop/6th Sem/DL/Dataset_Math/train'\n",
    "validation_data_dir = 'C:/Users/naman/Desktop/6th Sem/DL/Dataset_Math/validation'\n",
    "test_data_dir = 'C:/Users/naman/Desktop/6th Sem/DL/Dataset_Math/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(os.listdir(train_data_dir))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining image dimensions and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 64, 64\n",
    "batch_size = 32\n",
    "num_classes = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\naman\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42749 images belonging to 14 classes.\n",
      "Found 5337 images belonging to 14 classes.\n",
      "Found 5356 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naman\\AppData\\Local\\Temp\\ipykernel_41704\\3443314172.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\naman\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\naman\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1335/1335 [==============================] - 400s 298ms/step - loss: 0.4315 - accuracy: 0.8650 - val_loss: 0.1978 - val_accuracy: 0.9369\n",
      "Epoch 2/5\n",
      "1335/1335 [==============================] - 252s 189ms/step - loss: 0.1382 - accuracy: 0.9568 - val_loss: 0.0845 - val_accuracy: 0.9755\n",
      "Epoch 3/5\n",
      "1335/1335 [==============================] - 256s 191ms/step - loss: 0.0910 - accuracy: 0.9717 - val_loss: 0.0829 - val_accuracy: 0.9736\n",
      "Epoch 4/5\n",
      "1335/1335 [==============================] - 256s 192ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.0585 - val_accuracy: 0.9814\n",
      "Epoch 5/5\n",
      "1335/1335 [==============================] - 262s 196ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.0382 - val_accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27b1472eb60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=5, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42749 images belonging to 14 classes.\n",
      "Number of classes: 14\n",
      "Classes: ['add', 'divide', 'eight', 'five', 'four', 'multiply', 'nine', 'one', 'seven', 'six', 'subtract', 'three', 'two', 'zero']\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/naman/Desktop/6th Sem/DL/Dataset_Math/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')  # Change to 'binary' for binary classification\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('math_symbols_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = 'math_symbols_classifier.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 7s 38ms/step - loss: 0.0381 - accuracy: 0.9878\n",
      "Validation Loss: 0.038076382130384445\n",
      "Validation Accuracy: 0.9878208637237549\n"
     ]
    }
   ],
   "source": [
    "validation_generator.reset() \n",
    "validation_results = model.evaluate(validation_generator)\n",
    "\n",
    "# Displaying the evaluation results\n",
    "print(\"Validation Loss:\", validation_results[0])\n",
    "print(\"Validation Accuracy:\", validation_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 17s 100ms/step - loss: 0.0382 - accuracy: 0.9875\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Displaying training and testing accuracies\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_results[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(test_generator)\n",
    "\n",
    "# Displaying training and testing accuracies\n",
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Testing Accuracy:\", test_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image URL Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "image_url = 'https://wumbo.net/symbols/plus/feature.png'\n",
    "response = requests.get(image_url)\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above one else Below one (If above doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "image_url = 'https://wumbo.net/symbols/plus/feature.png'\n",
    "response = requests.get(image_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # Display the image\n",
    "    img.show()\n",
    "else:\n",
    "    print(f\"Failed to download the image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step\n",
      "class1: 1.0\n",
      "class2: 0.0\n",
      "class3: 0.0\n",
      "class4: 0.0\n",
      "class5: 0.0\n",
      "class6: 0.0\n",
      "class7: 0.0\n",
      "class8: 0.0\n",
      "class9: 0.0\n",
      "class10: 0.0\n",
      "class11: 0.0\n",
      "class12: 0.0\n",
      "class13: 0.0\n",
      "class14: 0.0\n"
     ]
    }
   ],
   "source": [
    "def predict_image_url(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    \n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    \n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    img = img.resize((64, 64))\n",
    "\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    class_labels = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
    "    decoded_predictions = dict(zip(class_labels, predictions.flatten()))\n",
    "\n",
    "    for label, score in decoded_predictions.items():\n",
    "        print(f'{label}: {score}')\n",
    "\n",
    "image_url = 'https://wumbo.net/symbols/plus/feature.png'\n",
    "predict_image_url(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Sign Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "Raw Predictions: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "class1: 1.0\n",
      "class2: 0.0\n",
      "class3: 0.0\n",
      "class4: 0.0\n",
      "class5: 0.0\n",
      "class6: 0.0\n",
      "class7: 0.0\n",
      "class8: 0.0\n",
      "class9: 0.0\n",
      "class10: 0.0\n",
      "class11: 0.0\n",
      "class12: 0.0\n",
      "class13: 0.0\n",
      "class14: 0.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'C:/Users/naman/Desktop/6th Sem/DL/math_symbols_classifier.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'C:/Users/naman/Desktop/6th Sem/DL/Paint Images (Predictions)/Add.png'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "\n",
    "# Decode predictions based on your custom class labels\n",
    "class_labels = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
    "decoded_predictions = dict(zip(class_labels, predictions.flatten()))\n",
    "\n",
    "# Print the predictions\n",
    "for label, score in decoded_predictions.items():\n",
    "    print(f'{label}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide Sign Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "Raw Predictions: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "class1: 0.0\n",
      "class2: 1.0\n",
      "class3: 0.0\n",
      "class4: 0.0\n",
      "class5: 0.0\n",
      "class6: 0.0\n",
      "class7: 0.0\n",
      "class8: 0.0\n",
      "class9: 0.0\n",
      "class10: 0.0\n",
      "class11: 0.0\n",
      "class12: 0.0\n",
      "class13: 0.0\n",
      "class14: 0.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'C:/Users/naman/Desktop/6th Sem/DL/math_symbols_classifier.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'C:/Users/naman/Desktop/6th Sem/DL/Paint Images (Predictions)/Divide.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "print(\"Raw Predictions:\", predictions)\n",
    "\n",
    "# Decode predictions based on your custom class labels\n",
    "class_labels = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
    "decoded_predictions = dict(zip(class_labels, predictions.flatten()))\n",
    "\n",
    "# Print the predictions\n",
    "for label, score in decoded_predictions.items():\n",
    "    print(f'{label}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero Number Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "class1: 0.0\n",
      "class2: 0.0\n",
      "class3: 0.0\n",
      "class4: 0.0\n",
      "class5: 0.0\n",
      "class6: 0.0\n",
      "class7: 0.0\n",
      "class8: 0.0\n",
      "class9: 0.0\n",
      "class10: 0.0\n",
      "class11: 0.0\n",
      "class12: 0.0\n",
      "class13: 0.0\n",
      "class14: 1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'C:/Users/naman/Desktop/6th Sem/DL/math_symbols_classifier.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'C:/Users/naman/Desktop/6th Sem/DL/Paint Images (Predictions)/Zero.png'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "\n",
    "# Decode predictions based on your custom class labels\n",
    "class_labels = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
    "decoded_predictions = dict(zip(class_labels, predictions.flatten()))\n",
    "\n",
    "# Print the predictions\n",
    "for label, score in decoded_predictions.items():\n",
    "    print(f'{label}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eight Number Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n",
      "class1: 0.0\n",
      "class2: 0.0\n",
      "class3: 1.0\n",
      "class4: 0.0\n",
      "class5: 0.0\n",
      "class6: 0.0\n",
      "class7: 0.0\n",
      "class8: 0.0\n",
      "class9: 0.0\n",
      "class10: 0.0\n",
      "class11: 0.0\n",
      "class12: 0.0\n",
      "class13: 0.0\n",
      "class14: 0.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'C:/Users/naman/Desktop/6th Sem/DL/math_symbols_classifier.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'C:/Users/naman/Desktop/6th Sem/DL/Paint Images (Predictions)/Eight.png'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "\n",
    "# Decode predictions based on your custom class labels\n",
    "class_labels = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
    "decoded_predictions = dict(zip(class_labels, predictions.flatten()))\n",
    "\n",
    "# Print the predictions\n",
    "for label, score in decoded_predictions.items():\n",
    "    print(f'{label}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Number Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024B009C4D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "class1: 0.0\n",
      "class2: 0.0\n",
      "class3: 0.0\n",
      "class4: 0.0\n",
      "class5: 0.0\n",
      "class6: 0.0\n",
      "class7: 0.0\n",
      "class8: 0.0\n",
      "class9: 0.0\n",
      "class10: 0.0\n",
      "class11: 0.0\n",
      "class12: 1.0\n",
      "class13: 0.0\n",
      "class14: 0.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'C:/Users/naman/Desktop/6th Sem/DL/math_symbols_classifier.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'C:/Users/naman/Desktop/6th Sem/DL/Paint Images (Predictions)/Three.png'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "\n",
    "# Decode predictions based on your custom class labels\n",
    "class_labels = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
    "decoded_predictions = dict(zip(class_labels, predictions.flatten()))\n",
    "\n",
    "# Print the predictions\n",
    "for label, score in decoded_predictions.items():\n",
    "    print(f'{label}: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
